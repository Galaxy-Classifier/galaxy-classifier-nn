# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X8dy_XuNm40LFdnAagOtj0rFijnaaZb5
"""
from __future__ import absolute_import #To make it compatible with python3
from __future__ import print_function


import glob
import cv2
import keras
import matplotlib.pyplot as plt
import numpy as np
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Dense, Dropout, Flatten
from keras.layers.advanced_activations import LeakyReLU
from keras.models import Sequential
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelBinarizer
from keras.models import Model, load_model
from sklearn.metrics import confusion_matrix


width, height = 100, 100


def extract_data(path):
    data = []
    files = glob.glob(path)
    for myFile in files:
        image = cv2.imread(myFile)
        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        im_resized = cv2.resize(gray_image, (width, height), interpolation=cv2.INTER_LINEAR)
        data.append(im_resized)

    return np.array(data)

np.random.seed(0)

espiral = extract_data("./data/Espiral/*.jpg")
elliptical = extract_data("./data/Elliptical/*.jpg")
lenticular = extract_data("./data/Lenticular/*.jpg")


x_test = np.concatenate([espiral, elliptical, lenticular])
y_test = np.concatenate(
    [np.full(len(espiral), 'espiral'), np.full(len(elliptical), 'elliptical'), np.full(len(lenticular), 'lenticular')])

x_train, x_test, y_train, y_test = train_test_split(x_test, y_test, test_size=0.2, random_state=13)

x_train = x_train.reshape(x_train.shape[0], width, height, 1).astype('float32')
x_test = x_test.reshape(x_test.shape[0], width, height, 1).astype('float32')
x_train /= 255
x_test /= 255

input_shape = (width, height, 1)

print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

# convert class vectors to binary class matrices
encoder = LabelBinarizer()
y_train = encoder.fit_transform(y_train)
y_test = encoder.fit_transform(y_test)

batch_size = 256
epochs = 500
num_classes = 3

# model = Sequential()
# model.add(Conv2D(32, kernel_size=(3, 3), activation='linear', padding='same', input_shape=input_shape))
# model.add(LeakyReLU(alpha=0.1))
# model.add(MaxPooling2D((2, 2), padding='same'))
# model.add(Dropout(0.25))
# model.add(Conv2D(64, (3, 3), activation='linear', padding='same'))
# model.add(LeakyReLU(alpha=0.1))
# model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
# model.add(Dropout(0.25))
# model.add(Conv2D(128, (3, 3), activation='linear', padding='same'))
# model.add(LeakyReLU(alpha=0.1))
# model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
# model.add(Dropout(0.4))
# model.add(Flatten())
# model.add(Dense(128, activation='linear'))
# model.add(LeakyReLU(alpha=0.1))
# model.add(Dropout(0.3))
# model.add(Dense(num_classes, activation='softmax'))

# model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])

# train = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))
# model.save("./galaxiasCNN.h5")

# accuracy = train.history['acc']
# val_accuracy = train.history['val_acc']
# loss = train.history['loss']
# val_loss = train.history['val_loss']
# epochs = range(len(accuracy))
# plt.plot(epochs, accuracy, 'bo', label='Training accuracy')
# plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')
# plt.title('Training and validation accuracy')
# plt.legend()
# plt.figure()
# plt.plot(epochs, loss, 'bo', label='Training loss')
# plt.plot(epochs, val_loss, 'b', label='Validation loss')
# plt.title('Training and validation loss')
# plt.legend()
# plt.show()

model = load_model('./galaxiasCNN.h5')


score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])


res = model.predict(x_test)

res_confusion = res
y_test_confusion = y_test

y_test = encoder.inverse_transform(y_test)
res = encoder.inverse_transform(res)
correct = np.where(res == y_test)[0]

print("Encontro %d labels correctos" % len(correct) + " de " + str(len(x_test)))

for i, correct in enumerate(correct[:9]):
    plt.subplot(3, 3, i + 1)
    plt.imshow(x_test[correct].reshape(width, height), cmap='gray', interpolation='none')
    plt.title("Predicted {}, Class {}".format(res[correct], y_test[correct]))
    plt.tight_layout()
plt.show()

incorrect = np.where(res != y_test)[0]
print("encontro %d labels incorrectos" % len(incorrect))

for i, incorrect in enumerate(incorrect[:9]):
    plt.subplot(3, 3, i + 1)
    plt.imshow(x_test[incorrect].reshape(width, height), cmap='gray', interpolation='none')
    plt.title("Predicted {}, Class {}".format(res[incorrect], y_test[incorrect]))
    plt.tight_layout()
plt.show()

target_names = ["Class {}".format(i) for i in range(num_classes)]
print(classification_report(y_test, res, target_names=target_names))

matrix = confusion_matrix(y_test, res, labels=["espiral", "elliptical", "lenticular"])
print(matrix)